## abstract

双手操作在机器人技术中非常重要，但是存在问题：

1. 协调两个机械臂的固有复杂性 (导致多模态动作分布)

   ==解决：采用扩散模型，高效表示多模态，用可扩展的Transformer来处理多模态输入的异质性并捕获机器人数据的非线性和高频性==

2. 训练数据的稀缺性

   解决：引入物理上可解释的统一动作空间，统一各种机器人的动作表示，同时保留原始动作的物理意义，**促进学习可迁移的物理知识**

结论：表现出对未见过的物体和场景的零样本泛化能力，能够理解并执行语言指令，通过1到5个示例快速学习新技能，并高效处理复杂、灵巧的任务

## 1.介绍



1. **双手操作对机器人完成现实任务至关重要**，在实际应用中，有效的操作策略应当具备对未见场景（如新物体和场景）的泛化能力。

   但是目前，仅具备有限的泛化能力，且在复杂任务中表现不佳。使其具备泛化能力的一个方向是==在大规模数据集上发明一种基于模仿学习的基础模型==

2. **开发一个双手操作的基础模型很困难**，原因有：针对特定双臂机器人的可用数据稀少，硬件成本高。

   解决：先在广泛的多机器人数据集上与训练，然后在目标双臂机器人上收集的小规模数据集上微调，==从其他机器人的数据集中学习可迁移屋里知识的潜力。

3. **仍然存在2个关键技术挑战**

   1. 首先一个具有泛化能力的基础模型，在表达能力和可扩展性上需要有高性能。双手操作中，动作空间的维度是单手的两倍，带来了更高程度的多模态动作分布。

      所以模型==需要具备足够表达能力，去捕捉动作分布中的多模态特性==。

      而且，模型架构还需要有效处理来自不同模态的输入，如文本、图像、动作。此架构还必须有可扩展性，在大规模机器人数据上可以稳定训练。

   2. 数据的异质性：不同机器人的物理结构和动作空间的定义差异，导致异质性。

      这个会导致多机器人训练中，出现负迁移，以及阻碍策略泛化。

      现有方法要么舍弃动作空间不同的机器人数据，要么保留不同机器人间结构一致的数据，导致==数据的损失==。

4. RDT：具有强泛化能力的最大规模双手操作基础模型

   ​	RDT采用==diffusion transformers==作为其可扩展性的主干网络，专门设计了语言引导的视觉条件双手操作策略。

   ​	RDT利用==扩散模型==在建模复杂分布的能力，==从海量数据中捕捉双手操作的全部模态特征。==

   ​	可扩展性上，transformer为主干网络，精心设计多模态编码消除各种模态之间的异质性。

   ​	为表征机器人数据中的，**固有的非线性动态、高频变化、不稳定的数值范围**，对DiT结构修改，包括MLP解码，改进的归一化条件，以及交替条件注入，为进一步支持RDT在异质数据上的训练，提出==物理可解释的统一动作空间==，这是一种适用于多种夹持臂机器人的统一动作格式，该格式缓解了不同机器人之间可能存在的冲突，同时保留了原始动作的物理意义。

结论：在多机器人数据集上对RDT模型进行了预训练，将其扩展至1.2B参数；为进一步增强其双手能力，在一个自行收起的多任务双手数据集上，对RDT微调。在实验中，全面评估RDT在双手操作与机器人基础模型中的表现。



RDT在多个具有挑战性的任务中表现优异，其成功率较基线提高了56％。尤其是RDT在零样本和少样本（1～5个示例）条件下对新物体、场景、指令甚至技能展现出了出色的**泛化**能力。RDT还能够完成需要**精细操作**的任务，如用操纵杆控制机器狗。最后，消融研究表明，扩散建模、大模型规模和大数据量均对其卓越性能有显著贡献。

## 2.相关工作

1. 基于学习的双手操作。

   动作空间的高维性，加剧了数据的稀缺性以及多模态行为的复杂性。  **双手的多模态特性**

2. 机器人基础模型

   基础模型在通过过任务，通用型的训练中展示了广泛的行为泛化能力，这些模型在多任务机器人数据集上进行训练。

   将大型视觉-语言模型调整为直接预测动作，优点：泛化到新物体与任务方面表现优异，但在双手操作应用中因动作空间离散化导致量化误差与动作不协调。

   **提升精读，扩散模型被应用为连续控制**

## 3.问题的产生与挑战

- 使用ALOHA双臂机器人作为目标机器人

- 考虑了语言条件的基于视觉的双手操作这一具体任务。形式化来说，给定语言指令l,策略在时间t呈现观察值ot，随后产生动作at，以控制两只机器人手臂完成l所指定的目标。

  ![image-20241028210419951](C:/Users/%E5%8D%8E%E7%9B%96%E5%B0%86%E5%80%BE/AppData/Roaming/Typora/typora-user-images/image-20241028210419951.png)

  $a_t$是下一时刻本体感知$z_{t+1}$的子集

- 双手操作中的具体任务通常包含多个元素：技能（如动词“抓取”或“擦拭”）、物体（如名词“瓶子”或“桌子”）、场景（即任务发生的环境），以及描述技能执行方式的模态（如“用左手抓取瓶子”）。==给定一个新任务，实际的策略需要能够泛化到未曾出现在训练数据中的新元素。==

- 通过模仿学习训练一个基础模型策略以实现泛化能力。预训练+微调，解决数据少的问题，以利用多种机器人数据，将数据量扩大三个数量级。

  目标：利用多机器人数据来增强模型在双手操作中的泛化能力。



挑战：

1. 如何设计强大的架构

   必须具备足够表达能力捕捉动作分布中的多模态性；需要具备可扩展性，要处理来自不同模态(文本、图像、动作等)的异构输入。

2. 如何在各种各样的数据上训练

   多机器人数据有异构性问题，不同机器人的物理结构和动作空间可能存在很大差异

   要么限制在动作空间相似的子集机器人、要么仅保留共享相同结构的输入子集

## 4.rdt模型

![image-20241028212219905](C:/Users/%E5%8D%8E%E7%9B%96%E5%B0%86%E5%80%BE/AppData/Roaming/Typora/typora-user-images/image-20241028212219905.png)

- **扩散建模**

  给定语言指令$l$,观察$O_t$，可能有多种可能的动作$a_t$来继续执行任务。如果将其建模为映射$(l,o_t) \rightarrow a_t$,在训练数据中回归这些元组，会导致策略学习到动作模式下的平均值，导致分布外的动作。

  因此采取建模连续的条件分布$p(a_t|l,o_t)$，扩散模型在表现力与采样质量上出色，但是高维数据采样慢(图像)，但是设定下，$a_t$维度远低于图像，只需要最小的采样开销。

  ==将扩散模型应用于机器人任务面临挑战==，因为机器人物理量(动作与本体感知)与图像/视频数据的固有特性不同，机器人物理量变化以非线性动态为特征，且可能因物理交互(碰撞、材料阻尼)发送高频变化。      因此必须对当前的扩散模型进行调整，以捕获机器人数据的不稳定性、非线性。

  **使用扩散模型做出决策前，先采用一个完全噪声动作，执行K次去噪步骤**，得到来自$p(a_t|l,o_t)$的一个干净的动作样本$a^{0}_t$。

  ![image-20241029205333546](C:/Users/%E5%8D%8E%E7%9B%96%E5%B0%86%E5%80%BE/AppData/Roaming/Typora/typora-user-images/image-20241029205333546.png)

  1. 生成噪声样本
  2. 逐步去噪
  3. 可学习的去噪网络，将带噪声的样本$a^{k}_t$转换为更接近真实的目标动作
  4. 去噪损失函数，最小化此函数，逐步学会移除噪声，生成精确的动作样本
  5. 动作块的批量预测，提高时间上的异质性，模型预测一组动作——动作块

  

- 异构多模态的输入的编码

  结构不同

  - 低维输入      表示机器人的物理量，包括本体感知、动作块、控制频率。
  - 图像输入      高维，提取紧凑表示，采取一个图像-文本对齐的预训练视觉编码器SigLIP
  - 语言输入     使用异构基于transformer的语言模型训练 编码

  信息量不同

  - 不同模态的数据包含不同的信息量
  - 在编码过程中采取一定概率、独立随机对每个多模态的输入进行掩码，防止模型过度依赖某一特定输入。
  
- $f_\theta$的网络结构

  选择Tranformer作为可扩展的在主干网络，进行以下修改

  - QKNorm与RMSNorm    

    输入的机器人物理量数值范围不稳定，导致梯度不稳定与数值溢出问题，因此==加入QKNorm==，避免在计算注意力时出现数值不稳定；此外，该问题是一个时间序列预测任务，而LayerNorm会导致token偏移与注意力偏移，破坏==时间序列的对称性==，将LayerNorm替换为没有居中操作的RMSNorm。不修改会导致不稳定，甚至出现爆炸现象。

  - MLP解码器

    为提高对非线性机器人动作的近似能力，将最终的线性解码器替换为非线性的MLP解码器，作为从潜在空间回到物理空间的因施工和

  - 交替条件的注入(ACL)

    图像与语言输入作为条件，具有高维度且长度不固定，使用交叉注意力来适应不同长度的条件，图像tokens会比文本tokens多，因此掩盖文本相关信息，削弱模型的指令遵循能力，因此==在连续层的交叉注意力中交替注入图像和文本tokens，而不是在每一层中同时注入两者。==

### 4.2数据

- 共享的统一动作空间

  为了在异构机器人数据上训练，提供一个共享的统一动作空间，为多机器人动作提供统一的格式

  >机器人的原始动作空间到统一动作空间的映射应具备物理可解释性，且每个维度都应具有明确的物理含义。这可以鼓励模型从不同的机器人数据中学习共享的物理规律，从而提高从不同机器人数据中学习的效率

  设计了一个统一的空间，涵盖了大多数具有夹持臂机器人的主要物理量。如图3左侧所示，**我们将机器人的动作空间嵌入该统一空间，通过根据其物理含义将原始动作向量的每个元素填充到统一动作空间向量的相应位置**，其余位置则进行填充处理

- 收集全面的多任务双臂数据集

  我们需要在目标机器人上收集一个多任务的双臂数据集用于微调

  1) 在数量上，我们收集了6000多条轨迹，使得我们的数据集成为目前最大双臂数据集之一；
  2) 在全面性上，我们考虑了300多个具有挑战性的任务，涵盖了大多数操作任务类型，从拾取和放置到插拔电缆，甚至包括书写数学公式；
  3) 在多样性上，我们准备了100多个具有不同大小和材质的刚性和非刚性物体，并在15种不同的房间和光照条件下进行操作。
  4) 利用GPT-4-Turbo（Achiam et al., 2023）重写人工注释的指令，以增加文本的多样性

## 5.实验

通过真实机器人实验回答以下问题：

- Q1：RDT是否能在零样本情况下泛化到未见过的物体与场景
- Q2：RDT对未见模态的指令跟随能力在零样本情况下有多有效
- Q3：RDT能否在少样本学习中快速掌握未见过的能力
- Q4：RDT是否具有完成精细任务的能力
- Q5：大模型尺寸、大量数据和扩散建模是否有助于提升RDT的性能

### 5.1实验设置

- 任务：选择7个具有挑战性的任务评估RDT在不同维度上的泛化能力与表现

- 数据：使用预训练与微调数据集

- 模型训练与微调：RDT模型的规模扩展到1.2B参数

- baselines：引入机器人基础模型和双臂操作的最先进Baselines  ACT,OpenVLA等

- 指标和硬件：成功率为主要指标，计算公式：成功的试验次数/总实验次数

  洗杯子任务、倒水任务、交接任务handover、叠短裤任务、机器人狗任务

- 消融实验：为回答问题5，对模型尺寸、预训练、建模方法进行了消融研究

  RDT(原版)

  RDT(回归) 不使用扩散建模RDT，使用确定性回归  映射$(l,o_t)\rightarrow a_t$

  RDT(小型)：不采用大量参数，166M参数

  RDT(从0开始)：不进行预训练的RDT，直接从微调阶段从0开始训练

### 5.2结果分析

1. RDT在各方面都优于其他基线。这是因为RDT采用了强大的网络架构的扩散建模，能够准确地建模多模态动作的分布，而离散化和VAE则分别在准确性和表现力方面有所欠缺。
2. 此外，大规模预训练后大量的参数为模型提供了丰富的先验知识，大大提升了泛化能力。以下是详细分析：



- Q1，Q2:   RDT能够在零样本情况下泛化到未见物体、场景和模态。

  RDT在未见场景中仍然具有较高的成功率，与已见场景的表现差异不大。而其他基线则无法完成整个任务。

  RDT精确理解了操作手和水量，尽管它从未见过“一三分之一”或“三分之二”这样的词语。正是由于大规模预训练，使得RDT见过大量不同的物体、场景和指令，从而具备了如此强的零样本泛化能力。

- Q3：

  RDT可以通过少样本学习快速掌握新技能。在交接和叠短裤任务中，RDT通过==少样本学习掌握了交接和折叠的新技能==，这些动作模式与已知技能有很大不同，而其他模型的成功率几乎为零。

- Q4

  RDT能够处理灵巧的任务。在机器人狗任务中，RDT精确控制了推操纵杆的角度，而其他模型则导致机器人狗偏离。

  因为==扩散建模==结合强大的网络架构能够建模==多模态和非线性动作分布==，使动作精度满足灵巧任务的要求。

- Q5

  大模型尺寸、大量数据和扩散建模都是模型优异表现的重要因素

  **表2显示，如果缺少其中任一因素，性能会显著下降**

  特别是RDT（从零开始）在未见物体和场景上的表现较差，这表明预训练知识对泛化能力至关重要。



## 6.总结

本文针对数据稀缺性和双臂操作复杂性不断增加的挑战，提出了机器人扩散变换器（RDT），一种用于语言条件视觉-运动模仿学习的扩散基础模型。

该模型在广泛的多机器人数据集上进行了预训练，并在自收集的双臂操作数据集上进行了微调。我们还提出了一个具有**物理可解释性的统一动作空间**，以统一不同机器人的动作表示，从而增强模型的鲁棒性和可转移性。

相比现有方法，RDT不仅在灵巧的双臂操作能力和指令跟随方面取得了显著提升，还在几次学习（few-shot learning）和零次学习（zero-shot generalization）上展现了出色的性能，能够推广至未见过的物体和场景。







## 7.附录

### 附录 A：动作分块技术

由于学习到的策略不完美，动作预测中的错误会随着历史决策数量的增加而积累。这可能导致机器人偏离训练分布，进入难以恢复的状态 

因此倾向于一次性预测多个动作，$p(a_{t:t+T_a}|l,o_t)$，一个动作块，对于提高时间一致性，避免机器人动作突变有好处



### 附录 B：架构细节

多模态输入的编码

- 低维输入：

  本体感知 $z_t$和噪声动作块$\tilde{a}_{t:t+T_a}$ 首先被嵌入到统一动作空间中。该空间用于在不同机器人之间统一 $z_t$ 和 a $\tilde{a}_{t:t+T_a}$ 的表示。然后，它们通过一个共享的 MLP 编码为令牌空间，因为它们具有相似的物理意义。这种连续编码可以避免精度损失

  对于频率 c和扩散时间步长 k，我们分别通过两个 MLP 将它们编码到令牌空间，最终得到长度为1+$T_a$+1+1的输入令牌序列

- 图像输入：

  使用冻结的 SigLIP 对 RGB 图像进行编码，并利用额外的 MLP 将输出投射到令牌空间中。

- 语言输入：

  冻结的 T5-XXL 编码，并使用 MLP 将输出投射到令牌空间

  在计算语言令牌的注意力时，我们应用语言注意力掩码以屏蔽批处理中附加的填充令牌。在训练过程中，每个模态输入以 10% 的概率被独立地屏蔽。

fθ 的网络结构

- 编码完成后，将低维输入的令牌传递到主网络中
- 加入了交叉注意力，每个注意力层中添加了 QKNorm，将每个 LayerNorm 替换为 RMSNorm，提高训练稳定性。
- 在每个 DiT 块的交叉注意力层中，我们交替注入语言和图像令牌，而非同时注入，以避免两种模态之间的令牌不平衡问题
- 经过 L 个 DiT 块后，我们对输出进行归一化，并通过 MLP 解码器将其投射回动作空间。

### 附录 C：具有物理可解释性的统一动作空间

该统一动作空间的维度为 128

描述了该统一动作空间向量中每个元素的含义。对于特定的机器人，原始动作向量中的每个元素根据其物理意义填充到统一动作向量的相应位置，其余位置填充为零。

![image-20241030135643087](C:/Users/%E5%8D%8E%E7%9B%96%E5%B0%86%E5%80%BE/AppData/Roaming/Typora/typora-user-images/image-20241030135643087.png)

如关节位置、末端执行器的6D位姿、速度等。
